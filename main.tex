% This is a template for seminar papers in the courses by Prof. Margrit Gelautz. There are important informations within this document, so please have a look at it at the beginning thorougly! When "TODO" is written, it means that there are changes you need to do here. When "COMMENT" is written, it means that we are trying to explain the LaTeX code for you.

\documentclass[titlepage, 12pt]{article} % The document gets initialized.
\newcommand{\open}[1]{\textcolor{red}{#1}} % When you write: \open{} the text in brackets is red.

% COMMENT: Useful packages
\usepackage[english]{babel} % Language setting
\usepackage[a4paper,top=3cm,bottom=3cm,left=4cm,right=4cm,marginparwidth=1.75cm]{geometry} % Set page size and margins
\usepackage{amsmath, graphicx, gobble, array, xcolor, soul}
\usepackage[colorlinks=true, allcolors=blue]{hyperref} % Creates colored links
\usepackage{tabularx}
\usepackage{pdflscape}

\setlength\parindent{0pt} % This removes the indents

% TODO: Please fill in your information here
\newcommand{\paperTitle}{Cost Effective Real Time Motion Capture for 3D Avatars}
\newcommand{\studentName}{Manuel Eiweck}
\newcommand{\matriculationNumber}{01633012}
\newcommand{\studyCode}{UE 066 932}
\newcommand{\studentEmail}{manuel.eiweck@tuwien.ac.at}
\newcommand{\seminarNumber}{193.179}
\newcommand{\seminarName}{Seminar in Visual Computing}
\newcommand{\supervisor}{Prof. Dr. Margrit Gelautz}
\newcommand{\semester}{2025W}
\newcommand{\dueDate}{Draft: 7.12.2025 \\ Final: 5.1.2026}

% COMMENT: This is where your title page is formatted, don't change anything here.
\title{
\textbf{\paperTitle}}
\author{\\ 
    \textbf{\studentName} \\ \\ \\ 
    Matriculation Number: \matriculationNumber \\ 
    Study Code: \studyCode \\ 
    E-mail: \studentEmail \\ \\ 
    \seminarNumber \\
    \seminarName \\
    Supervisor(s): \supervisor \\
    Semester: \semester \\
    \newline
}
\date{\dueDate}

%TC:ignore
% #########################################
% COMMENT: The actual document and content starts here. 
\begin{document}
\maketitle

% #########################################
% COMMENT: The declaration of independent work is inserted here. Please read it again.
\section*{Erklärung zur Verfassung der Arbeit}
Hiermit erkläre ich, dass ich diese Arbeit selbständig verfasst habe, dass ich die verwendeten Quellen und Hilfsmittel vollständig angegeben habe und dass ich die Stellen der Arbeit - einschließlich Tabellen, Karten und Abbildungen -, die anderen Werken oder dem Internet im Wortlaut oder dem Sinn nach entnommen sind, auf jeden Fall unter Angabe der Quelle als Entlehnung kenntlich gemacht habe. \\
Ich erkläre weiters, dass ich mich generativer KI-Tools lediglich als Hilfmittel bedient habe und in der vorliegenden Arbeit meine gestalterischer Einfluss überwiegt. Im Anhang “Übersicht verwendeter Hilfsmittel” habe ich alle generativen KI-Tools gelistet, die verwendet wurden, und angegeben, wo und wie sie verwendet wurden. Für Textpassagen, die ohne substantielle Änderung übernommen wurden, habe ich jeweils die von mir formulierten Eingaben (Prompts) und die verwendete IT-Anwendung mit ihrem Produktnamen und Versionsnummer/Datum angegeben. \\\\
% \open{IMPORTANT: Read this thoroughly so that you make no mistakes here! (it is in German for legal reasons, but you'll find a way to translate it)} % TODO: Remove this before the final submission.

% #########################################
% TODO: Here you should write your abstract.

\newpage
\addcontentsline{toc}{section}{Abstract} % This adds Abstract to the Table of Contents. 
\section*{Abstract}

3D Motion capture for the professional industry is traditionally being done with a marker based approach in complex studio setup including multiple cameras and special suits to achieve high accuracy.
While this might suit certain needs such as film production and offline computer animation, other use-cases require real-time processing and high mobility instead of high accuracy.
Furthermore, expensive investments in a motion capture studio create a high entry barrier for smaller organizations and individual creators. 
Therefore, this seminar papers tries to find a meaningful balance between high-cost high accuracy setups and low cost high mobility setups.\\\\
Human motion capture covers a large research field, various kinds of input data, output data a lack of common terminology and standards make it hard to compare approaches. 
To give an overview of the possibilities in motion capture methods 5 different methods are examined in detail.
Benchmark datasets are presented alongside different output file formats and evaluation metrics.
Afterwards, a use-case for 3D Live concerts using virtual avatars (VTuber) is described, and motion capture tasks are formulated. 
With a certain use-case and various kinds of approaches in mind a qualitative comparison and quantitative comparison of 8 different methods is done. 
Lastly, a potentially suitable motion capture method is described, and current challenges are explained.




% Motion capture technology has traditionally relied on expensive multi-camera marker-based systems that require fixed studio setups and significant infrastructure investment. However, recent advances in deep learning and computer vision have enabled cost-effective alternatives suitable for smaller organizations, individual creators, and applications requiring portability. This seminar paper provides a comprehensive overview of current state-of-the-art motion capture methods that balance accuracy, cost, and real-time performance for practical applications such as virtual avatar animation in live performances.

% We examine five prominent approaches representing different sensor modalities and architectures: OpenPose, a widely-adopted real-time 2D multi-person pose estimator; DeMoCap, which uses low-cost depth sensors for marker-based 3D tracking; XNect, enabling markerless 3D multi-person tracking from a single RGB camera; Ultra Inertial Poser, combining IMU sensors with ultra-wideband technology for wearable-based tracking; and MAMMA, a recent method achieving near gold-standard accuracy with markerless multi-camera setups. Additionally, we discuss relevant datasets, data formats, and industry standards that support these approaches. We then evaluate these methods against specific requirements for real-time motion capture in live concerts with virtual avatars.

% While no single existing approach fully satisfies all requirements for this use case, recent developments demonstrate significant improvements toward making motion capture more accessible to broader audiences. The trade-offs between accuracy, cost, portability, and real-time performance vary across methods, making the selection of appropriate techniques dependent on specific application constraints and intended use cases.

% #########################################
% COMMENT: This is where your table of content is automatically generated.

\newpage
\tableofcontents
%TC:endignore

% #########################################
% COMMENT: Here, your real content of the seminar paper starts.

\newpage
\pagenumbering{arabic}

% COMMENT: We recommend to create separate files for the separate sections. It simplifies the main.tex file and makes it easier to keep a good overview. You can use \input to include the content of the other file on the same page. Or you can use \include if you want to start a new page with the content.

% \section*{Introduction to this Document}
% Hello all. This document is supposed to offer you some insights into LaTeX, scientific writing, and give some tips for writing your seminar paper. The content is specifically catered for this seminar and not just generic LaTeX information. If you are looking for a more basic introduction, you can have a look at this \href{https://www.overleaf.com/learn/latex/Learn_LaTeX_in_30_minutes}{LaTeX tutorial}. Please read through the \textbf{whole document thoroughly}, because it focuses on typical mistakes of previous semesters. Also read through the \textbf{introductory slides} again. Please also note: the following is based on my personal experience, can contain mistakes or accidental misinformation.
% \\\\
% Concerning the template, you don't need to use this template specifically. You are also free to use a different one, but then pay attention that you include all the important aspects which are mentioned in the preliminary slides.

\pagebreak


\input{sections/Introduction}
\input{sections/Methods}
\input{sections/Tech}
\input{sections/TaskDescription}
\input{sections/Comparision}
\input{sections/Conclusion}

%TC:ignore
% \input{text-files/01-LatexIntroSeminar}
% \input{text-files/02-MoreTips}
%TC:endignore
% ######################################################
% ## CAN ADD OTHER SUPPLEMENTAL MATERIAL AS ANOTHER APPENDIX (THEN "APPENDICES" NOT "APPENDIX") ##

\newpage
%TC:ignore
\addcontentsline{toc}{section}{Appendix}
\section*{Overview of Generative AI Tools Used}
\textbf{AI-Tool:} GitHub Copilot via VSCode\\
\textbf{Purpose:} Grammar correction and sentence completion/rewrite. \\
\textbf{Input:} The LaTeX files from this document are used as context for the model. \\
\textbf{Output:} - \\
\textbf{Reflection:} I had GitHub Copilot enabled as I usually do for coding, writing technical documentation etc. While it started being useful I noticed fast that it tends to write long sentences and you have to be careful to not change the original meaning. Also while it sounded professional it was obvious that the content wasn't self written. Therefore, I stopped about halfway through and completely disabled the extension. \\

\noindent\rule[7pt]{\linewidth}{0.4pt}
\textbf{AI-Tool:} GitHub Copilot via VSCode (Claude Haiku 4.5)\\
\textbf{Purpose:} Creation of an draft of both of the Comparision Tables\\
\textbf{Input:} The LaTeX files from this document are used as context for the model. Along with simple prompts like 'Check my described methods in the 2. chapter methods and update my table in Comparision.tex' \\
\textbf{Output:} Latex Table\\
\textbf{Reflection:} As creation of tables in LaTeX is pretty verbose it saved some time, as it handles columns, formats, size and crossreferences. The actual text content in the first table was changed manually by myself. For the second table I first wrote down the benchmark results from the papers as a latex comment, and let it autofill from the AI into the table, then I verified the changes manually.\\


\noindent\rule[7pt]{\linewidth}{0.4pt}
\textbf{AI-Tool:} GitHub Copilot via VSCode (Claude Haiku 4.5)\\
\textbf{Purpose:} Creation of an draft for the abstract\\
\textbf{Input:} The LaTeX files from this document are used as context for the model. Along with simple prompt like 'Can you write me a draft for my abstract' \\
\textbf{Output:} Draft of the abstract\\
\textbf{Reflection:} Served as a good start. Just summarized the content did not start to get the readers' attention by trying to engage them.\\


% Note: You can display your contents how ever you like, e.g. via a table etc.
%TC:endignore

% ######### REFERENCE PAGE AUTOMATICALLY GENERATED FROM .BIB FILE AND IN TEXT CITATIONS

\newpage
\addcontentsline{toc}{section}{References}
\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}