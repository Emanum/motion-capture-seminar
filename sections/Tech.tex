\section{Motion Capture in Industry}
\label{chapter_tech}
An applied motion capture systems can be seen as a pipeline with various software modules in between. A transformation from the real human motion through tracking and processing to the final result like a rendered 3D video, animations in a game engine, motion data as an HCI device or other real time applications is done.
In a quickly evolving field like motion capture it is especially important to have common file formats, standards and protocol to exchange the tracking information in order to allow methods to focus on a single task.
Standardized interfaces allow us to develop a modular software architecture and upgrade our tracking methods later down the line without having to adapt our entire motion capture to render pipeline. 
This allows commercial and open source integrations into other software to be developed. \\
Furthermore, we need benchmark datasets to measure and compare different approaches quantitatively. This allows appropriated methods to be picked based on a certain use case. In addition, it enables accurate evaluations for new approaches.

\subsection{Tracking Format}

A simple solution to exchange tracking information is to store it as a set of certain keypoints in 2D or 3D coordinates and then serialize it either as plain text or in binary file format. 
Various approaches use different body locations for their keypoints often as a result of different tracking methods. For marker based approaches these are usually equal to the marker position attached on the body.
While there are no defined standards in the research community we have seen approaches using similar keypoint position as common datasets are using. This can be observed in the dataset HDM05 \cite{cg-2007-2} and COCO Pose \cite{coco} with their usage in OpenPose \cite{openPose_docs}. However, OpenPose also proposed their own skeleton modal body25.\\
A common proprietary format used in the 3D graphics industry is FBX \cite{fbx_format}. It contains alongside mesh information, material and texture also skeletal animation information that can be used to store motion capture data. 
Other similar multi asset format are Collada \cite{Collada_format} originally developed by Sony or the more recent GLTF \cite{gltf_format} both are now maintained by the Khronos Group.
While these formats have support for meshes, they are targeted towards general 3D models and are therefore not optimized for storing human bodies.
A mesh and skeleton based storage format limits the capabilities of some approaches. In order to predict entire body shapes and the movement of skin and fine facial details either a new mesh would need to be stored for each key frame or an increase of the skeleton count would be required. \\
SMPL \cite{loper_smpl_2015} improves the storage options for such approaches. It is a format specialized to capture human skinned models. Instead of storing a complex mesh for the entire body SMPL defines a base mesh and skinning equations to further refine the mesh.
It formulates a function which takes tracking parameters along with a pre learned model as input and output a final vertex mesh for each key frame.
SMPL comes with the weights for the model which is trained by analyzing thousands of body scans.  
% Therefore, trading runtime speed against storage capacity. 
SMPL-X \cite{SMPLX} improves the original model by adding tracking for hands and expressive face details as well as using an updated dataset for training.
Both offer along the actual storage and model mechanism tools to calculate a final mesh. This is done via vertex based linear blend skinning with learned corrective blend shapes.\\


VRM File Format \cite{VRM_consortium}
VRM Press Release \cite{vrm_press_release}

VMC Protocol Specification \cite{vmc_protocol_specification}


Sony Mocap Protocol https://www.sony.co.jp/en/Products/mocopi-dev/en/documents/Home/TechSpec.html

Webcam Motion Capture + Sony Mocap
https://www.sony.co.jp/en/Products/mocopi-dev/en/documents/Home/TechSpec.html


\subsection{Datasets and Metrics}
AMASS: Archive of Motion Capture as Surface Shapes \cite{AMASS:ICCV:2019}

CMU Panoptic Studio datase

Human3.6M, HumanEva, and MPI-INF-3DHP dataset


DanceDB (included in AMASS)

UnrealEgo Akada et Al 2022\\

Hi4D dataset \cite{yin2023hi4d} \\
MuPoTS-3D benchmark dataset \cite{singleshotmultiperson2018}\\

Focus on close interaction 
Harmony4D \cite{Harmony4D}\\
CHI3D \cite{CHI3D}\\
Rich \cite{Rich}

Focus on complex postitions:\\
MOYO \cite{MOYO}\\

Metrics:
The most common metric for evaluation is MPJPE (Mean Per Joint Position Error) usually measure in millimeter (mm). This describes the distance between the ground truth 3D position and the tracked position. 
A variation of this is RMSPJPE (Root Mean Squared Per Joint Position Error) that uses the root-mean-square instead of a simple mean.\\
For approaches that output mesh, surface or SMPL data MPVE (Mean Per Vertex Error) is used instead. This measures the error at each mesh vertex.
Other metrics are PCP3D (Percentage of Correct Parts 3D) which tracks the amount of correct classified body parts. 
Similar to this PCK3D (Percentage of Correct Keypoints 3D) tracks the amount of correct classified keypoints. 
A pose/keypoint is correctly classified when the euclidean distance between the estimated pose/keypoint and the ground truth pose/keypoint is below a certain threshold $\alpha$. 
Based on the percentage metric a recall and precision can be calculated which in turn allows a metric called mAP or AP (mean Average Precision) to be defined. This is often further refined by adding the threshold to the metric, for example AP\textsubscript{50} for an average precision with a threshold of 50mm.
MRPE (Mean of the Root Position Error) compares the position of a root keypoint in absolute values (mm).
For approaches using IMU sensors flickering is an issue, therefore jitter is measured here as well. This describes the mean jerk (time derivate of acceleration) for all body joints often measured in $km/s^3$. Which can be perceived as smoothness of the animation.